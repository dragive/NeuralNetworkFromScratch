{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ActivationFunctions:\n",
    "        \n",
    "    def ReLu(data):\n",
    "        temp = np.array(data)\n",
    "        return np.maximum(0,temp)\n",
    "        \n",
    "    def Sign(data):\n",
    "        temp = np.array(data)\n",
    "        return np.sign(temp)\n",
    "            \n",
    "    def Sigmoid(data):\n",
    "        temp = np.array(data)\n",
    "        return 1/(1+np.exp(-temp))\n",
    "    def Default(data):\n",
    "        temp = np.array(data)\n",
    "        return temp\n",
    "    def SoftMax(data):\n",
    "        temp = np.exp(np.array(data))\n",
    "        return temp/np.sum(temp)\n",
    "        \n",
    "\n",
    "class Layer:\n",
    "    \n",
    "    def __init__(self,shape,function=ActivationFunctions.Default) -> None:\n",
    "        assert len(shape)==2\n",
    "        assert isinstance(shape[0],int) and isinstance(shape[1],int)\n",
    "        assert shape[0]>0 and shape[1]>0\n",
    "        self.function=function\n",
    "        self.shape = shape\n",
    "\n",
    "        self._init_matrix()\n",
    "\n",
    "    def __init__(self,shape_x:int,shape_y:int,function=ActivationFunctions.Default) -> None:\n",
    "        assert shape_y>0 and shape_x>0\n",
    "\n",
    "        self.shape = (shape_x,shape_y)\n",
    "        self.function=function\n",
    "        self._init_matrix()\n",
    "\n",
    "    def _init_matrix(self):\n",
    "        self.martix = np.random.randn(self.shape[0],self.shape[1])\n",
    "\n",
    "\n",
    "    def forward(self,data,function=ActivationFunctions.Default):\n",
    "        \n",
    "        if function in [None,ActivationFunctions.Default]:\n",
    "            function = self.function\n",
    "        if function == None:\n",
    "            return np.dot(data,self.martix)\n",
    "        else:\n",
    "            return function(np.dot(data,self.martix))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.layers=[]\n",
    "        self.structure=[]\n",
    "        self.learningFactor=0.02\n",
    "    def addLayer(self,numberOfNeurons:int,function=ActivationFunctions.Default):\n",
    "        assert numberOfNeurons>0\n",
    "        # todo to validate function\n",
    "        self.layers.append((numberOfNeurons,function))\n",
    "        \n",
    "    def compileModel(self):\n",
    "        assert len(self.layers)>=2\n",
    "        \n",
    "        for i in range(len(self.layers)-1):\n",
    "            self.structure.append(Layer(self.layers[i][0],self.layers[i+1][0],self.layers[i+1][1]))\n",
    "    def forward(self,data):\n",
    "        output=np.array(data)\n",
    "        for i in self.structure:\n",
    "            output = i.forward(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function ActivationFunctions.Sigmoid at 0x7fcd4caddd30>\n",
      "<function ActivationFunctions.Sigmoid at 0x7fcd4caddd30>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.38368753])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =Model()\n",
    "model.addLayer(5,ActivationFunctions.Sigmoid)\n",
    "model.addLayer(5,ActivationFunctions.Sigmoid)\n",
    "model.addLayer(1,ActivationFunctions.Sigmoid)\n",
    "\n",
    "model.compileModel()\n",
    "# for i in range(len(model.structure)):\n",
    "#     print(model.structure[i].shape,end=f\" {model.structure[i].function}\\n \")\n",
    "model.forward(np.array([1,2,3,4,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ActivationFunctions.Sign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ActivationFunctions.SoftMax(np.linspace(-1,1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Taka jest docelowa funckja LOSS czyli taka którą minimalizujemy.\n",
    "\n",
    "```1```- indidator function https://www.wikiwand.com/en/Indicator_function\n",
    "\n",
    "```i``` iteruje sie po obserwacjach\n",
    "\n",
    "```c``` iteruje sie po klasach\n",
    "\n",
    "$p_{model} [y_i \\in C_c ]$ prawdopodobieństwo, że obserwacja i należy do klasy c\n",
    "\n",
    "$-1/N*\\Sigma_{i=1} ^N \\Sigma_{c=1} ^C 1_{y_{i} \\in C_{c}} log(p_{model}[y_i \\in C_{c}]) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python385jvsc74a57bd0916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
